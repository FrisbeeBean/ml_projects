{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 33884,
          "sourceType": "datasetVersion",
          "datasetId": 1864
        }
      ],
      "dockerImageVersionId": 31041,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Food_Classification_PyTorch",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "import kagglehub\n",
        "kmader_food41_path = kagglehub.dataset_download('kmader/food41')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "fOZURXnG3MoS"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN ON FOOD-101 DATASET\n",
        "\n",
        "I am Rishabh Jain and this is my attempt at classifying the foods in the food-101 dataset"
      ],
      "metadata": {
        "id": "iT-NESca3MoU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### STEP 1: Importing the Libraries"
      ],
      "metadata": {
        "id": "f6N9mXOi3MoV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pickle"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T05:23:06.806004Z",
          "iopub.execute_input": "2025-06-18T05:23:06.806316Z",
          "iopub.status.idle": "2025-06-18T05:23:07.231905Z",
          "shell.execute_reply.started": "2025-06-18T05:23:06.80629Z",
          "shell.execute_reply": "2025-06-18T05:23:07.230996Z"
        },
        "id": "odN3j84X3MoV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### STEP 2: Correcting the Dataset\n",
        "\n",
        "The dataset we have used as input conatins the labels separate from the images so we have to do an extra step which makes a new dataset with the food name as the folder name of the images"
      ],
      "metadata": {
        "id": "Pn07HHF03MoW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def make_new_data(txt_file, s_folder, d_folder):\n",
        "    os.makedirs(d_folder, exist_ok=True)\n",
        "    with open(txt_file, 'r') as f:\n",
        "        for line in f:\n",
        "            full_path = line.strip()\n",
        "            food_name = full_path.split('/')[0]\n",
        "            dst_folder = os.path.join(d_folder, food_name)\n",
        "            os.makedirs(dst_folder, exist_ok=True)\n",
        "            src_path = os.path.join(s_folder, full_path + '.jpg')\n",
        "            dst_path = os.path.join(dst_folder, os.path.basename(full_path) + '.jpg')\n",
        "            try:\n",
        "                os.symlink(src_path, dst_path)\n",
        "            except FileExistsError:\n",
        "                pass\n",
        "\n",
        "make_new_data('/kaggle/input/food41/meta/meta/train.txt', '/kaggle/input/food41/images', 'train')\n",
        "make_new_data('/kaggle/input/food41/meta/meta/test.txt', '/kaggle/input/food41/images', 'test')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T04:42:28.314891Z",
          "iopub.execute_input": "2025-06-18T04:42:28.315277Z",
          "iopub.status.idle": "2025-06-18T04:42:31.224165Z",
          "shell.execute_reply.started": "2025-06-18T04:42:28.315251Z",
          "shell.execute_reply": "2025-06-18T04:42:31.223372Z"
        },
        "id": "HOBP0q3y3MoW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### STEP 3: Getting the data, processing it and loading it"
      ],
      "metadata": {
        "id": "DiYCs1Wl3MoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "#transform functions composed\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "#getting the dataset\n",
        "train_data = ImageFolder(root = \"train\" , transform = transform)\n",
        "test_data = ImageFolder(root = \"test\" , transform = transform)\n",
        "train_size = len(train_data)\n",
        "test_size = len(test_data)\n",
        "\n",
        "#loading data\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True,num_workers=os.cpu_count(),pin_memory=True)\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=False,num_workers=os.cpu_count(),pin_memory=True)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T04:46:42.6206Z",
          "iopub.execute_input": "2025-06-18T04:46:42.621298Z",
          "iopub.status.idle": "2025-06-18T04:48:25.99173Z",
          "shell.execute_reply.started": "2025-06-18T04:46:42.621274Z",
          "shell.execute_reply": "2025-06-18T04:48:25.991217Z"
        },
        "id": "V3_8bzjp3MoX"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### STEP 4: Making the Model"
      ],
      "metadata": {
        "id": "ASjH3jof3MoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3,32,3,1,1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(2,2)\n",
        "        self.conv2 = nn.Conv2d(32,64,3,1,1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(2,2)\n",
        "        self.conv3 = nn.Conv2d(64,128,3,1,1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool3 = nn.MaxPool2d(2,2)\n",
        "        self.conv4 = nn.Conv2d(128,256,3,1,1)\n",
        "        self.bn4 = nn.BatchNorm2d(256)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool4 = nn.MaxPool2d(2,2)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(256*14*14,1024)\n",
        "        self.dp1 = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(1024,512)\n",
        "        self.dp2 = nn.Dropout(0.5)\n",
        "        self.out = nn.Linear(512,101)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.bn4(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool4(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.dp1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.dp2(x)\n",
        "        return self.out(x)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T04:48:33.53664Z",
          "iopub.execute_input": "2025-06-18T04:48:33.537341Z",
          "iopub.status.idle": "2025-06-18T04:48:33.545792Z",
          "shell.execute_reply.started": "2025-06-18T04:48:33.537319Z",
          "shell.execute_reply": "2025-06-18T04:48:33.545057Z"
        },
        "id": "0iSADVeb3MoY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### STEP 5: Setting the optimizer and the loss function"
      ],
      "metadata": {
        "id": "rYpMxnjo3MoY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CNN().to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
        "lossfn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T05:03:41.372148Z",
          "iopub.execute_input": "2025-06-18T05:03:41.372471Z",
          "iopub.status.idle": "2025-06-18T05:03:41.878782Z",
          "shell.execute_reply.started": "2025-06-18T05:03:41.372443Z",
          "shell.execute_reply": "2025-06-18T05:03:41.878258Z"
        },
        "id": "Mq3EFCF63MoY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### STEP 6: Main code of the model"
      ],
      "metadata": {
        "id": "6kZ2XLZ53MoY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, lossfn, optimizer, num_epochs):\n",
        "    train_losses = []\n",
        "    train_accs = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        trainloss = 0.0\n",
        "        traincorrect = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = lossfn(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            trainloss += loss.item()*inputs.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            traincorrect += (predicted == labels).sum().item()\n",
        "\n",
        "        avgtrainloss = trainloss / train_size\n",
        "        trainacc = traincorrect / train_size\n",
        "        train_losses.append(avgtrainloss)\n",
        "        train_accs.append(trainacc)\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {avgtrainloss:.4f} , Train Acc: {trainacc:.4f}\")\n",
        "\n",
        "    return train_losses, train_accs"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T05:03:45.702206Z",
          "iopub.execute_input": "2025-06-18T05:03:45.702789Z",
          "iopub.status.idle": "2025-06-18T05:03:45.70807Z",
          "shell.execute_reply.started": "2025-06-18T05:03:45.70277Z",
          "shell.execute_reply": "2025-06-18T05:03:45.707303Z"
        },
        "id": "lWIkTf7c3MoY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### STEP 6: Training the model and saving the weights"
      ],
      "metadata": {
        "id": "ALvudgc23MoZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses, train_accs = train(model,train_loader,lossfn,optimizer,num_epochs=15)\n",
        "with open(\"food_101_model.pkl\", \"wb\") as f:\n",
        "    pickle.dump(model.state_dict(), f)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T05:26:50.139909Z",
          "iopub.execute_input": "2025-06-18T05:26:50.140595Z",
          "iopub.status.idle": "2025-06-18T06:18:22.268762Z",
          "shell.execute_reply.started": "2025-06-18T05:26:50.140566Z",
          "shell.execute_reply": "2025-06-18T06:18:22.2677Z"
        },
        "id": "Eurq_8fd3MoZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### STEP 7: Testing the model and saving predictions in submissions.csv"
      ],
      "metadata": {
        "id": "nnrVdsDW3MoZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def testmodel(model, testloader):\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    indices = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_id, (inputs, _) in enumerate(testloader):\n",
        "            inputs = inputs.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            preds.extend(predicted.cpu().numpy())\n",
        "            indices.extend(range(batch_id * testloader.batch_size, batch_id * testloader.batch_size + inputs.size(0)))\n",
        "\n",
        "    df = pd.DataFrame({'Id': indices,'Predicted': preds})\n",
        "    df.to_csv(\"submissions.csv\", index=False)\n",
        "\n",
        "testmodel(model,test_loader)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T06:18:42.113342Z",
          "iopub.execute_input": "2025-06-18T06:18:42.113945Z",
          "iopub.status.idle": "2025-06-18T06:19:44.957463Z",
          "shell.execute_reply.started": "2025-06-18T06:18:42.113915Z",
          "shell.execute_reply": "2025-06-18T06:19:44.956444Z"
        },
        "id": "zr2kLyiX3MoZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### STEP 8: Plotting train loss and accuracy plots"
      ],
      "metadata": {
        "id": "80B0kcAH3MoZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training_history(train_losses, train_accs):\n",
        "    epochs = range(1, len(train_losses) + 1)\n",
        "\n",
        "    plt.figure(figsize=(12,5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, train_losses, 'b-', label='Train Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Train Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, train_accs, 'b-', label='Train Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Train Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "plot_training_history(train_losses, train_accs)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T06:19:53.344168Z",
          "iopub.execute_input": "2025-06-18T06:19:53.344714Z",
          "iopub.status.idle": "2025-06-18T06:19:53.657069Z",
          "shell.execute_reply.started": "2025-06-18T06:19:53.344685Z",
          "shell.execute_reply": "2025-06-18T06:19:53.656347Z"
        },
        "id": "DPombvuC3MoZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### STEP 9: Show predictions of some images"
      ],
      "metadata": {
        "id": "jb07vbHi3Moa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def imageshow(img, title):\n",
        "    img = img.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    img = std * img + mean\n",
        "    img = np.clip(img, 0, 1)\n",
        "    plt.imshow(img)\n",
        "    plt.title(title)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "class_names = test_data.classes\n",
        "def show_top5_preds(model, testloader, classnames, num_images):\n",
        "    model.eval()\n",
        "    indices = random.sample(range(len(testloader)), num_images)\n",
        "    with torch.no_grad():\n",
        "        for id in indices:\n",
        "            image,_ = test_data[id]\n",
        "            inputs = image.unsqueeze(0).to(device)\n",
        "            probs = torch.softmax(model(inputs),dim = 1)\n",
        "            top5_probs, top5_indices = torch.topk(probs, k = 5, dim = 1)\n",
        "            top5 = zip(top5_indices[0].cpu().numpy(), top5_probs[0].cpu().numpy())\n",
        "            top5_str = \"\\n\".join([f\"{classnames[class_id]}: {prob:.3f}\" for class_id, prob in top5])\n",
        "            imageshow(image, top5_str)\n",
        "\n",
        "show_top5_preds(model,test_loader, class_names, num_images = 2)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:03:12.804418Z",
          "iopub.execute_input": "2025-06-18T07:03:12.805262Z",
          "iopub.status.idle": "2025-06-18T07:03:13.182054Z",
          "shell.execute_reply.started": "2025-06-18T07:03:12.805226Z",
          "shell.execute_reply": "2025-06-18T07:03:13.181245Z"
        },
        "id": "RhrPSRdb3Moa"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}